<!DOCTYPE html>
<html>
    <head>
        <title>Canadian Labour Market and Skills Researcher Network</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>
    <body>
        <h1>Canadian Labour Market and Skills Researcher Network</h1>
        <hr><!-- comment -->
        <div align="center">
            <b>Working Paper No. 90</b>
            <b>How Important are School Principals in the Production of Student Achievement?</b>
            <b>Elizabeth DhueyUniversity of Toronto</b>
            <b>ustin SmithWilfrid Laurier University</b>
        </div>
        <div align="center">
            <p>CLSRN is funded by the Social Sciences and Humanities Research Council of Canada (SSHRC)<br/> under its Strategic Knowledge Clusters Program. Research activities of CLSRN are carried out<br/> with support of Human Resources and Skills Development Canada (HRSDC). All opinions are <br/> those of the authors and do not reflect the views of HRSDC or the SSHRC<br/></p>
        </div>
        <div align="center">
            <p>How Important Are School Principals in the Production of Student Achievement?</p>
        </div>
        <div align="center">
            <p>Elizabeth Dhuey<br/> Centre for Industrial Relations and Human Resources<br/> Department of Management University of Toronto<br/></p>
        </div>
        <div>
            <p>Justin Smith<br/> Wilfrid Laurier University<br/> Department of Economics<br/></p>
        </div>
        <div>
            <h2>Abstract</h2>
            <p>As school leaders, principals can influence student achievement in a number of ways, such as: hiring and firing teachers, monitoring instruction, and maintaining student discipline, among others. We measure theeffect of individual principals on gains in student math and reading achievement between grades four and seven.  We  estimate  that  a  one  standard  deviation  improvement  in  principal  quality  can  boost  student  performance  by  approximately  0.2 standard  deviations  in  both  math  and  reading.  We  also  show  that  principal experience does not exert a significant influence on student performance. Our results imply that isolating  the  most  effective  principals  and  allocating  them  accordingly  between  schools  can  have  a  significant positive effect on reducing achievement gaps.</p>
            <p>*We  thank  Kelly  Bedard,  Mati  Dubrovinsky,  David  Johnson,  Harry  Krashinsky,  Abigail  Payne,  Simon  Woodcock, and various seminar participants for helpful comments. </p> 
        </div>
        <div>
            <h2>1 I. Introduction</h2>
            <p>The summer of 2008 saw widespread media coverage of controversial Washington D.C. school chancellor Michelle Rhee and her move to fire roughly 40 school principals in her district. Many of the schools in question were failing to meet the academic proficiency standards of the No Child Left Behind Act, and this change in school leadership was meant to help these struggling schools improve their performance. Not only does this move highlight the value that school districts place on quality leadership within a school, but it also demonstrates an underlying belief that principals have an effect on student achievement within their schools. As the main administrator in a school, the principal is responsible, among other things, for maintaining and improving teacher quality, monitoring and enforcing student conduct, and ensuring the curriculum is properly implemented. However, despite the importance of these functions in contributing to the educational experience, much of the economics research to this point has focused on teacher quality rather than principal quality.</p>
            <p>In this paper we quantify the importance of principals in the production of student test score gains between fourth and seventh grade using principal fixed effects estimated from longitudinal administrative data from the province of British Columbia (BC), Canada. Principal fixed effects measure the impact of all unchanging characteristics of a principal that are transferrable between schools, such as leadership ability, personality, and gender. We obtain these estimates for math and reading scores using a value-added model that controls for observable time-varying student, school, and neighborhood factors, along with fixed school effects. The frequent mobility of principals between schools in BC allows us to identify principal effects using within school variation, which is important because school fixed effects remove the influence of fixed school characteristics that might bias estimated principal effects if principals sort across schools based on those attributes. We also extend the model to allow for “match effects,” where part of the principal effect is portable across schools, and part depends on the school where they are employed. Finally, we estimate the effect of experience as a principal within a school (which we call tenure), and overall experience as a principal on student achievement. </p>
        </div>
        <div>
            <p>2 We estimate that a one standard deviation move up the distribution of principal quality leads to an improvement of approximately 0.2 standard deviations in both math and reading score gains. When we extend the model to include match effects, we find that roughly half of that effect is due to the match between principal and school, and that the standard deviation of the match effects is 0.160. Given the importance of good principals and good matches between principals and schools, properly allocating principals to schools is an important policy consideration, especially in terms of reducing achievement gaps. In terms of principal experience, we find that more experienced principals and those with a longer tenure in a school have no significant impact on student performance. This implies that, at least in BC, what matters for student achievement is finding a principal with good fixed attributes and assigning that individual to the correct school.  </p>
        </div>
        <div>
            <h2>II. Existing Literature on the Effect of Principals</h2>
            <p> Despite the extensive literature on teacher quality, relatively little attention has been paid by economists to the importance of principals in the production of student achievement.1 The existing economics literature related to our research can be separated into three strands.2 The first focuses on estimating the overall effect of the principal on achievement, the second on the effects of specific principal attributes on achievement and the third on the effects of specific principal training programs3Most closely related to our research are two recent papers by Coelli and Green (forthcoming) and Branch, Hanushek, and Rivkin (2010) focus on the overall effect of the principal on achievement.4 Coelli and Green (forthcoming) use a sample of students entering grade 12 drawn from administrative data</p>
        </div>
        <div>
            
        </div>
        <div>
            <p>BC to estimate the effect of principals on high school graduation and grade 12 provincial exam scores in English.5 In their main analysis, they estimate the lower bound of the variance of principal effects on the outcomes above using the method formulated by Rivkin, Hanushek, and Kain (2005), which was originally used to estimate teacher effects. They find that moving one standard deviation up in the distribution of principal effects can improve both outcomes, but has a particularly significant effect on grade 12 English scores. They also estimate a dynamic model of principal effects and find that that a principal’s full impact is not immediate, but instead increases gradually over time. Even though we both draw our samples from BC data and estimate the dispersion of principal effects on outcomes, our research is best viewed as a complement to Coelli and Green (forthcoming) because of fundamental differences.The main difference is in the populations under analysis: we study elementary school students and they study high school students. Secondly, though our empirical strategies rely on similar identifying assumptions, they are different in that we use a value-added approach rather than a levels approach. We focus on value-added because our outcomes will depend on cumulative inputs from various sources. Finally, in addition to providing estimates of fixed principal effects, we also estimate match effects.Branch, Hanushek, and Rivkin (2010) use data from Texas to estimate the importance of principals on student math and reading test score gains using data from the first three years of a principal’s tenure at a school. In their main analysis, they estimate principal fixed effects in a value-added model, and present summary statistics based on those effects. They find a significant amount of dispersion in the principal effects overall, and that this dispersion is higher in low-income schools. They also find that principals in the middle of the quality distribution are generally more likely to stay at the school after three years, and that this pattern does not vary with the school’s poverty level. They support their conclusions that what they estimate is a principal quality effect by showing that when high quality principals lead schools, the teachers who exit are of comparably worse quality. While similar to our research, the main specification in Branch, Hanushek, and Rivkin (2010) excludes school fixed effects. </p>
        </div>
        <div>
            <p>Though they mention that variance estimates are similar when school effects are included, it is difficult to imagine that principal mobility is uncorrelated with school quality, so excluding these controls will confound the effects of principal and school.   The second strand of the literature on principal effects focuses on the relationship between principal observable characteristics and school performance. Many of these papers focus on the role of principal education and experience on school performance, and have found mixed results. In terms of education, some researchers find that a more educated principal worsens the school's performance (see Ballou and Podgursky, 1993 and Eberts and Stone, 1988), whereas other researchers find no relationship (see Clark, Martorell, and Rockoff, 2009). In addition, Eberts and Stone (1988) and Clark, Martorell, and Rockoff (2009) find a positive correlation between teaching experience and school performance, but Brewer (1993) finds no correlation. The third strand of the literature examines the effects of principal training programs. For example, Corcoran, Schwartz, and Weinstein (2009) show that principals trained in the New York City Aspiring Principals Program have positive effects on school performance. Clark, Martorell, and Rockoff (2009), however, find mixed evidence on the relationship between formal principal training/development programs and school achievement.  Our research adds to the principal literature in several ways. Our main contribution is to measure the effectiveness of individual principals within a framework that controls for potential confounding school factors. We also relax the restriction that principal effects are fixed across schools by estimating the contribution of the principal-school match to student achievement. There are many reasons to think that principal effectiveness depends on the school environment where they work, so this is an important step forward in determining why principals matter for student achievement. Finally, we are also able to explore the effect of principal tenure at a school and overall principal experience, as these factors have the potential to matter if principals tend to improve over time.</p>
        </div>
        <div>
            <h2>III. Education in British Columbia</h2>
            <p>The public school system in BC is very similar to other jurisdictions across Canada and the United States. There are 60 school districts in BC, many of which correspond to city boundaries in the populated areas (Vancouver and its surrounding area and Victoria). In the more rural areas, districts correspond to a much wider area. Prior to 2003, students attending public schools were required to attend the school located in their catchment area. Since 2003, legislation has existed that allows parents to choose any public school. However, it is not clear that this legislation has been successful in creating widespread public school choice (DeCicca and Smith, 2011). Approximately, 30 percent of students attend a middle or junior high school that begins in either sixth or seventh grade, and the other 70 percent attend a school whose grades extend through seventh grade and higher (Dhuey, 2011).  Therefore, the majority of the students in our sample will have the opportunity to stay at the same school between grade four and seven.6Each year since 1999, students in fourth and seventh grade are tested in reading, writing, and math using the Foundation Skills Assessment (FSA) tests. All students are expected to participate in the tests, with the exception of some ESL students and students with special needs. These tests are low stakes in the sense that no funding is tied to the outcome of these exams, nor do they contribute to student course grades. Therefore, despite recent work regarding teacher and principal cheating, principal cheating on these exams is unlikely, mainly due to the fact that principal compensation and school resources are set according to guidelines that are not based on student outcomes (Coelli and Green, forthcoming).  Principals in British Columbia are appointed by the school board, and their duties are outlined in various parts of the School Act from the Revised Statutes of BC and are specifically listed in BC Regulation 265/89 and the many amendments thereof. BC principals are typical of most principals across jurisdictions. They are responsible for carrying out orders from the school district or from the Ministry of Education, and they are also responsible for making sure the instructional practices of their school 6 We include a robustness check that includes only students that attend the same school (see Table 6, Panel D). The results are not substantially different. 
6 conform to the School Act. In addition, they are responsible for the smooth functioning of the province’s various standardized testing programs. Unlike some other jurisdictions, principals do not directly hire and fire teachers; instead they provide information to the school district about teacher performance, and any disciplinary action is then decided at this upper level. Finally, they carry out various administrative tasks such as making teacher timetables, maintaining school records, and monitoring the conduct of students.</p>
        </div>
        <div>
            <h2>IV. Empirical Specification</h2>
            <p>To estimate the principal effects, we use the following value-added model of students’ test scores.</p>
            <p>where  is the grade seven math or reading score for student i in school s with principal p;is the student’s corresponding grade four score;  is a vector of student-level characteristics; is a vector of school-level characteristics;  is a set of dummy variables equal to 1 if principal p has j years of experience in year t;   ,, and are fixed effects at the principal, school, and year level, respectively;  is an idiosyncratic error term.7To describe the effect of principals on student achievement, we examine summary statistics based on the set of principal fixed effects, in particular their standard deviation. These principal fixed effects are interpreted as the effect of each individual principal on achievement that is invariant across time, students, and schools conditional on other time-varying and time-invariant student and school-level factors. This effect will measure the impact of any fixed attribute of the principal, such as leadership ability, gender, education, and training.</p>
        </div>
        <div>
            <p>We estimate equation 1 using fixed effects methods, treating  as parameters to be estimated. Normally, fixed effects are used to control for unobserved heterogeneity when researchers are trying to identify other coefficients in the model. In that scenario, the fixed effects are generally never explicitly estimated, but rather swept away by a within transformation. Our primary focus, however, is on the estimates of the principal fixed effects themselves, which adds several complications in terms of estimation. If we first consider the case where we do not include the school effects, we cannot separately identify all of the principal effects when the model contains a constant (the “dummy variable trap”); an identifying restriction must be imposed. The most obvious restriction is to simply set one principal effect equal to zero. This is unsatisfactory for our purposes because it forces the interpretation of the remaining fixed effects to be deviations from the dropped principal, which is sensitive to which principal is dropped. Instead, we restrict the fixed effects to sum to zero as in Mihaly et al. (2010). With this restriction, the principal effects are interpreted as deviations from the average of the principal effects. The problem becomes more complicated when we include both principal and school effects. Principals and schools are implicitly separated into many disconnected groups because not every principal works at every school. Each group contains all principals that have ever worked at any school in the group, and all schools that have ever employed any principal in the group. Principals in one group are never observed working at a school in any other group, and schools in one group never employ a principal from any other group. When including school fixed effects, one principal effect in each group is not identified, and additional restrictions must be imposed.8 Following Mihaly et al. (2010), when the model contains principal and school effects, we restrict the principal effects to sum to zero within each group. The principal effects in this case are interpreted as deviations from the within-group mean.</p>
        </div>
        <div>
            <p>principals over time to contribute to estimation. This arises mainly through principal mobility across schools, but can also occur when new principals enter the sample. In the extreme case where a group contains exactly one principal and one school (i.e. the principal does not move and the school does not employ any other principal), principal effects are not identified and therefore not estimated. The reported standard deviations based on the school fixed effects specification use only identified principal fixed effects. Thus, principal mobility is crucial for our estimation. Fortunately there is enough mobility to identify an effect for most principals in the school effects model (see Table 1). Despite the fact that we can only identify principal effects for the subset of identified principals, it is our preferred specification because controlling for fixed school factors is crucial. We examine the difference between “identified” and “unidentified” principals in Section V.C.Our estimates of the standard deviation of the principal effects may be upwardly biased due tosampling error. As explained in Kane and Staiger (2002), and noted in Branch, Hanushek, and Rivkin (2010), Aaronson, Barrow, and Sander (2007), and Jacob and Lefgren (2005 and 2008), even in the absence of any real principal effect, we still might observe variations in the estimated effect due to random differences between samples of students. Such sampling variation is a problem particularly when a principal fixed effect is based on a small number of students. To correct for this, we adjust the standard deviation downward using an estimate of the variation of the sampling error.9 Following Aaronson, Barrow, and Sander (2007) and Jacob and Lefgren (2005 and 2008), we assume the estimated principal effect is the sum of the true effect and a mean-zero, independent, normally distributed error pppνδδ+=ˆ. Due to independence, the variance of the estimated principal effect is the sum of the variances of the true effect and the error 222ˆνδδσσσ+=. We obtain the true principal effect variance </p>
        </div>
        <div>
            <p>by subtracting the error variance from the variance of the estimated principal effect. Because  is unknown, we estimate it by taking the square of the average of the standard errors of .  In addition to shrinking our original estimate of the standard deviation of principal effects estimated above, we also compute the standard deviation of an Empirical Bayes estimate of the principal effects. As in Jacob and Lefgren (2005), if ),0(~2δσδNp, then conditional on observing our “noisy” estimate of the principal effect,ˆ δ p=δp+νp, a Bayesian estimate of the mean of the principal effect would shrink our existing estimates based on a signal to noise ratio:ppppEδσσσδδδνδδˆ]ˆ|[222*+== . If our estimate contains mostly noise, then the estimates shrink toward zero.10 Using our estimates of𝜎𝛿2  and , we can construct the Empirical Bayes estimate 𝛿𝑝  by substituting those values into the equation above. Estimates will shrink more toward zero the higher the noise matters relative to the signal</p>
        </div>
        <div>
            <h2>V. Data and Analysis Sample</h2>  
        </div>
        <div>
            <p>Our main datasets are three linked files obtained from the Ministry of Education in BC. The first contains observations on all students writing the FSA test in the period 1999 through 2006. For these students, we know the percentage score on each test, the school in which the test is written, and whether </p>
        </div>
        <div>
            <p>the student was “excused” from the test.12 Student scores are linked over time via an encrypted student identifier. Student test scores are linked via the student identifier to a file containing the administrative records of all public school students in BC from 1999–2006 in grades four to seven. These data include information on gender, aboriginal status, participation in Special Education or English as a Second Language (ESL) programs, and each student’s residential postal code. In urban areas, postal codes are very small area consisting sometimes of one side of a city block. In less-populated areas, they can coincide with part or all of a town. We use postal codes to link Dissemination/Enumeration Area (DA) level information from the Canada Census as proxies for students’ Socio-Economic Status (SES).13 DAs are relatively small areas that are designed to contain roughly 400–700 people, and as such act as a reasonable proxy for a student’s SES. We attach information on household income, average dwelling value, education levels, unemployment rates, ethnic and immigrant composition, and the age distribution of each DA.The third file contains information on all public schools in British Columbia from 1995 through 2006. For each school we know information such as what grades are offered, the number of teachers, and each school’s exact address and postal code. Most importantly, we know the name of the principal, which we use to create principal fixed effects in the econometric specification.14 To this dataset we append principal names and school numbers dating back to 1989, transcribed from the Public and Independent Schools Book, a document produced by the Ministry of Education in BC. These additional data allow us to create a more precise measure of principal experience.</p>
        </div>
        <div>
            <h2>B. Descriptive Statistics on Principals</h2>
            <p>We begin by analyzing descriptive statistics for the principals in our data, with a focus on mobility, which is key for our estimation strategy. In this section, we restrict our attention to the years 1999–2006, since those are the years for which we have data on school and student demographics. We also restrict the sample to elementary, middle, and elementary-secondary schools to keep the focus on the student population of interest. Table 1 contains basic statistics about the number, mobility and experience of principals in British Columbia. Between 1255 and 1362 principals are employed each year, and between 117 and 178 of them are newly hired into the system. The main factors affecting the number of principals hired each year are retirements in the previous year ( which depends on the age of those within the cohort of principals at that time) and school openings or closings in a particular year. Between 69 and 77 percent of principals stay in the same school from one year to the next. Eleven to fifteen percent moved to a different school within British Columbia and 10–18 percent leave thesample. This latter group includes those principals who retired, those who moved out of province, and those who stop working as a principal but remain in the system in some other capacity.  Each year, roughly one quarter of the sampled principals are in their first year of tenure at a school, and another quarter remain at the same school for five or more years. The other half remain at the same school between two and four years. This shows considerable turnover of principals within schools, which helps our estimation strategy because we need multiple principals at each school to be able to identify the principal fixed effects. Finally, about one third of principals are in their first three years of employment as a principal, and another third have been a principal for 10 or more years.</p>
        </div>
        <div>
            <h2>C. Regression Sample</h2>
            <p>12 C. Regression SampleBecause we estimate a value-added model in test scores, we restrict our focus to students who wrote both the fourth- and seventh-grade mathematics and reading exams.16 Since we observe test scores between 1999 and 2006, and since three years pass between each test, most such students are observed between 2002 and 2006. There are 229,337 students observed in the grade seven test data between 2002 and 2006. We drop 27,286 of these students (11.9 percent) who are not observed in all years between grades four and seven, and a further 14,692 students (6.5 percent) who do not have a valid test score in both years. We also drop 657 students (< 1 percent) who are missing school information in grades five or six . Finally, we drop 3,079 students (1.3 percent) who are in schools that have less than ten test takers. Our final analysis sample consists of 183,623 student observations .  The summary statistics in Table 2 regarding test scores, demographics, and neighborhood census characteristics are based on this sample of 183,623 students. The fourth- and seventh-grade math and reading test scores are standardized to have a mean of zero and standard deviation of one in the population. The means of these test scores are slightly positive in our analysis sample, which indicates that the students who were excluded from the samples scored marginally worse than the students who were included in the samples.As we explained in Section IV, in the school fixed effects model, principal effects are only identified for a subset of principals. In Table 3 we compare sample means of observable characteristics for identified and unidentified principals from the regression sample. Column 1 pools all principals, and columns 2 and 3 restrict the sample to identified principals and unidentified principals, respectively. On average, the identified principals have slightly less experience and have shorter tenure in schools. This is not surprising because a principal needs to be mobile to be included in our sample. The other differences are that unidentified principals are more likely to be in rural areas (where it is more difficult to move),</p>
        </div>
        <div>
            <p>The administrative rules governing principal mobility in BC are discussed in detail by Coelli and Green (forthcoming). They find that mobility is determined at the school district level and is generally overseen by the Superintendent of Schools. Of the 60 districts in BC, 14 are found to mention principalrotation somewhere in their district policies; these 14 districts are larger than average in size. Their main example of a district policy towards rotation comes from the Vancouver School Board, whose written procedure is to transfer principals between schools roughly every five years. Other districts are sometimes less precise, stating in their district policies minimum and maximum times until principal transfer, leaving much discretion to the school district. Smaller districts that do not have written rotation procedures are found not to have included them in the district policy because there are too few schools to make such a strategy work.18In Table 4 we empirically evaluate the determinants of principal mobility. We take a sample of all schools that offer the grade 7 FSA test between 1999 and 2006, and use a regression to relate principal mobility between those schools to observable characteristics of the principals and schools. We regress an indicator for a principal move between t and t+1 on school and neighborhood characteristics at time t (and in some specifications, t-1). In Columns 1-3 the dependent variable equals 1 only if the principal moves from one school to another school in the sample. In columns 4-6, the indicator equals 1 for any move, including switches to schools out of the sample or exits from the sample. Column 1 includes a full set of controls but excludes school fixed effects. Results show no evidence that principal turnover is related to any school and neighborhood characteristics, including math and reading test scores. Note in particular that the test score coefficients are very small and imprecise.19 The main significant predictors of mobility are principal experience indicator variables. When we add school effects in Column 2, the conclusions do not change. Column 3 adds lagged test scores, and there continue to be no significant relationships. The</p>
        </div>
        <div>
            <p>due to sampling error. Columns 2 and 7 add demographic and census control variables.20 Estimates shrinkslightly, but the story is largely unchanged. Interestingly, our estimates do not see the same kind of attenuation that was found in teacher effects when adding demographic control variables (see Aaronson, Barrow, and Sander 2007).  In Columns 3 and 8 we drop the principal effects that would be unidentified in a school fixed effects specification to assess the effect of limiting the sample of principals before explicitly including school fixed effects. This restriction decreases the number of principal effects estimated from 1323 to 1077. The standard deviation does not change dramatically compared to columns 2 and 7. This provides some evidence that our sample used to estimate both school and principal effects is not biased due to sample selection. Columns 4 and 9 report estimates when school fixed effects are added to the model. Including school fixed effects is preferred because it holds constant all fixed school components like curriculum, school size, fixed family, and some community characteristics in computing principal effects. This is important because these factors may be highly correlated with principal effects, and because both fixed school components and principal effects impact student achievement. The estimated standard deviations are 0.231 and 0.224, and the adjusted standard deviations are 0.196 and 0.188 for math and reading, respectively. As before, the F-test rejects that the within-school principal fixed effects jointly equal zero at the one percent level. Columns 5 and 10 show the Empirical Bayes estimates. These results indicate that an increase of one standard deviation increases math scores by 0.167 standardized units and reading scores by 0.158</p>
        </div>
        <div>
            <p>standardized units. Comparing the principal at the 75th percentile to the median gives a much more modest 0.076 unit increase for math scores and a 0.070 unit increase for reading. Note that when calculating Empirical Bayes estimates, the sampling error makes the variance of the estimates lower than the variance of the actual principal quality (see Jacob and Lefgren, 2005). Therefore, we adjust this variance upward by adding in our estimate of the variance of the sampling error. The adjusted estimates for math is an increase of 0.207 standardized units and an increase of 0.199 standardized units in reading. The results in Table 5 show that overall, individual principals can have a substantial impact on student achievement in reading and math. How large are these effects? One way to interpret their size is to compare them against other inputs to student cognitive ability. Using a similar research design, Rockoff (2004) estimates teacher fixed effects using one-year test score gains. He estimates that the unadjusted standard deviation of estimated teacher effects is roughly 0.21 in reading and 0.29 in math, and the adjusted effect is 0.10 for reading and math. Aaronson, Barrow, and Sander (2007) estimate a standard deviation of 0.13 for teacher effects on math scores in Chicago. Note that compared against these teacher effects, our magnitudes are likely larger in part because we use gains over three years rather than one year as in most other studies (see the results in Table 6 below).   What types of fixed principal characteristics might contribute to the effects we observe? Principals are not likely to have a direct impact on student performance through their teaching ability, as they generally do not interact directly with students in the classroom. Thus, principals affect students through indirect channels; the most likely such channels are through teachers and overall school policies such as those that include changes to the curriculum. Good principals will hire the best teachers and fire the worst (Jacob 2010), match teachers to students based on ability, set appropriate timetables, and evaluate/monitor teacher performance. Principals are also in charge of setting school-level policies on issues such as instruction and discipline. In addition, principals are responsible for acting as a liaison between the school and the district, a role which will involve passing information from school to district </p>
        </div>
        <div>
            <p>seven principal. The effects will be very similar to 1-year gains if the principal effects are linear. Columns 1 and 3 display the standard deviation and the adjusted standard deviation from equation 1 including the time with principal interactions. Columns 2 and 4 display both the Empirical Bayes standard deviation and adjusted standard deviation. The estimates in Panel A are 0.052-0.087 standard deviations lower thanthe corresponding estimates in Table 5. These estimates are the closest estimates to the single-year gains estimates from the teacher effect literature and have a similar magnitude to this literature.One problem with the results from Table 5 and the above robustness check is that they include effects for only grade seven principals. Students may have a different principal in grades 5 and 6, and these principals may impact grade 7 scores. In Panel B we generalize the principal effects in Panel A to equal to the number of years each student has been with any given principal between grades five and seven.22 Including the additional principals increases the number of principal effects we can identify to 1660 from 1323.23 T he estimates in Panel B are slightly larger than the estimates calculated in Table 5.   In Panel C we estimate the set of principal fixed effects using only students who had the same principal in grades five through seven but had a different principal in grade four.24 Using this sample, we can attribute most of the value added measure to the grade seven principal. These estimates are also slightly larger than the estimates found in Table 5. Panel D limits the sample to students who stayed in the same school between grades four and seven. The purpose of this exercise is to see if the results are robust to student sorting across schools in search of a better principal. We have mostly been concerned with principals choosing to work in the best schools, but an equally plausible, although less likely, situation is that parents locate near a school </p>
        </div>
        <div>
            <p>because of the principal. The results from this exercise are similar to the main results. This suggests that student sorting is not causing substantial bias in our results.    Finally, our results might be driven by trends in test scores over time, which would not be absorbed by our fixed effects, and could persist even though we control for time-varying factors. In Panel E, we add school-specific linear time trends to the specification. Estimation is problematic in this case because a school is observed for a maximum of five years, and it is therefore difficult to statistically estimate these trends. Indeed, we were not able to identify a trend for schools that had a different principal in each year in the sample, or were observed for too few years (100 schools out of 912). The results show a higher standard deviation in principal effects in both math and reading. A significant amount of the increase in dispersion is driven by noise, as evidenced by the difference between the adjusted and unadjusted standard deviations. These results suggest that if there is any principal sorting due to trends, then our main results understate the value of principals. C. Match EffectsOur analysis thus far provides estimates of principal effects that are fixed across schools (and time). It is entirely plausible, however, that a principal’s effectiveness varies across schools. These“match effects” might arise if a principal’s effect on student achievement depends on things like interactions with the existing teaching staff, demographic composition of the student body, location preference of the principal, or any other complementarity between the principal and school. If principals sort themselves into schools where they have good matches, our principal effect estimates will be biased upward since they partly measure the impact of fixed principal characteristics and partly the impact of the match. Match effects are also important in their own right because their existence implies that considering the school to which a principal is assigned is crucial in terms of improving student achievement in particular schools and reducing achievement gaps.</p>
        </div>
        <div>
            <p>21 In this section we provide estimates of principal-school matches. Woodcock (2008) outlines two different methods for estimation. The first is the orthogonal fixed effects estimator, which identifies match effects by imposing that they are orthogonal to the principal and school effects.25 This estimator has one major downside: it mechanically forces match effects to sum to zero for each principal and school. Thus, matches with one principal or school are assigned a zero match effect, which is not desirable. Therefore, while we provide orthogonal fixed effects estimates, we prefer the hybrid random effects estimator. This method avoids the issues with orthogonal fixed effects, but comes at the cost of imposing orthogonality between the principal, school, match, and residual.26Table 7 presents the match effects estimates. Columns 2 and 4 in Panel A report the standard deviations from the orthogonal fixed effects estimator,  alongside the results from our main specification in columns 1 and 3 for comparison. For both math and reading scores, the principal and school effects are identical regardless of whether match effects are included. The match effects themselves are small relative to the principal and school effects: the standard deviation is 0.033 in math and 0.034 in reading. Panel B of Table 7 presents the results of our preferred hybrid random effects estimator. For comparison, we also estimate the hybrid random effects model without match effects in columns 1 and 3. The standard deviation of the principal effects in columns 1 and 3 are much smaller than their corresponding fixed effect estimates from Panel A, but is of a similar magnitude to the Empirical Bayes estimates from Table 5. Columns 2 and 4 contain the hybrid random effects estimates with match effects. Here differences emerge in the size of the standard deviations. The standard deviation of the principal effect for math drops to 0.093, and the corresponding estimate for reading drops to 0.059. The school effect is roughly unchanged. Match effects are large with a standard deviation of about 0.160 for both</p>
        </div>
        <div>
            <p>math and for reading—roughly five times larger than the estimates derived from the fixed effects estimation. Match effects have important implications for policy. That match effects appear to matter more than fixed principal effects (given random effects estimates) on their own implies that policy makers could not simply assign “good” principals to any school and expect them to have the same impact. A principal’s effect depends on the school where they are located, so if principals are rotated across schools in part to help improve student performance, the key will be to assign them to a school with the best match so they will have maximum impact. These estimates must be considered somewhat cautiously, however, because estimating them requires pushing the data very hard and/or imposing some restrictions.Fortunately, even when match effects are included,  the fixed principal effects still exert a substantial effect on student outcomes, so assigning a principal to a school that is a good match will help bolster that effect</p>
        </div>
        <div>
            <p>22 math and for reading—roughly five times larger than the estimates derived from the fixed effects estimation. Match effects have important implications for policy. That match effects appear to matter more than fixed principal effects (given random effects estimates) on their own implies that policy makers could not simply assign “good” principals to any school and expect them to have the same impact. A principal’s effect depends on the school where they are located, so if principals are rotated across schools in part to help improve student performance, the key will be to assign them to a school with the best match so they will have maximum impact. These estimates must be considered somewhat cautiously, however, because estimating them requires pushing the data very hard and/or imposing some restrictions.Fortunately, even when match effects are included,  the fixed principal effects still exert a substantial effect on student outcomes, so assigning a principal to a school that is a good match will help bolster that effect.27D. Principal ExperienceThe effects of fixed principal characteristics on student achievement are the focus of this paper, but we also have data on principal experience, which is an important characteristic of principals that may impact student achievement. In our regressions, we separately analyze the effect on student performance of principal tenure in a school and overall principal experience. We model principal tenure with a set of dummy variables for each level of experience up to five years and a dummy for any amount of experience five years and over, with one year of experience as the excluded group. We model overall principal experience using dummies for groups of four to six, seven to ten, and ten or more years, with one to threeyears as the excluded group. With overall experience, these groupings reflect the fact that we are less interested in the yearly changes in experience, and more interested in comparing inexperienced to</p>
        </div>
        <div>
            <p>somewhat experienced to very experienced principals. With principal experience at a school, we are more interested in how one-year changes in experience affect student scores.Panel A of Table 8 reports the results from specifications that include our measures of principal tenure at a school. Columns 1 and 3 display estimates when school fixed effects are not included in the model. In these specifications, there is no distinct relationship between experience and student performance, except that principals who have been at a school for five years or longer boost test scores slightly. Including school fixed effects in columns 2 and 4 does little to change the pattern across years of experience, except that experienced principals no longer exert any influence on math scores.These results contrast with those of Clark, Martorell, and Rockoff (2009), who find that principal experience still matters with math scores, but less for reading scores when principal and school fixed effects are held constant.28 There are several factors that might explain differences in our results, most of which are speculative since we cannot formally test these differences. First, differences between the New York City and British Columbia school systems could be responsible. Their research suggests that New York City recently has placed a great amount of emphasis on their principals. This emphasis may not have been seen in British Columbia.29 A second explanation is differences in the degree to which sorting causes bias. Both our study and theirs control for similar demographics and other characteristics in addition to fixed school and principal factors, so this is not likely to be the issue. Panel B of Table 8 presents the results of using overall principal experience rather than school tenure. With no school fixed effects in the model, the most experienced principals increase student scores by 0.055 standard deviations in math and by 0.069 standard deviations in reading relative to the least experienced principals. Once we control for school effects, however, the pattern disappears, leaving no </p>
        </div>
        <div>
            <p>relationship between experience and test scores. Overall, we find no evidence of any systematic relationship between experience and student achievement.These results are interesting as they suggest that experience does not matter. This is important from a policy perspective since it suggests that if the goal is to boost performance of underperforming students, and reduce achievement gaps, a more effective approach would be to identify high-ability principals and then allocate them to schools, rather than relying on a principal to boost performance by gaining experience. </p>
        </div>
        <div>
            <h2>VIII. Conclusion</h2>
            <p>We estimate the impact of fixed principal characteristics on student performance. Results show that principals have a substantial impact on both math and reading scores. Our main results show that a one standard deviation shift up the principal quality distribution can increase achievement by approximately 0.2 standard deviations in math and reading. When we extend the model to allow the effectiveness of the principal to depend on the school where s/he is employed, our most robust model shows that a one standard deviation improvement in principal quality increases math scores by about 0.1 standardized units and reading scores by 0.06 standardized units. Additionally, a quality match improves student performance by approximately 0.15 standard deviations in math and in reading. We also estimate that a more experienced principal within a school or overall has no significant effect on student achievement.  These results have important implications for policy. The main implication is that shifting principals between schools has the potential to significantly reduce achievement gaps.30 Some of this improvement depends on where the principal works, but a sizable portion is portable across schools. Policy makers could identify the most effective principals, and allocate them between schools to potentially reduce achievement gaps. Alternatively, we could identify the best principals and dig deeper to</p>
        </div>
        <div>
            <p>earn more about the attributes that make them so effective. Information gleaned from that exercise could be used to train underperforming principals. What are the fixed characteristics that make one principal better than another? We cannot identify these in our data, but prior literature can shed some light on this issue. The results of Clark, Martorell, and Rockoff (2009) show that education level and pre-principal experience are not likely to be among the factors, while the evidence on training programs is mixed. Principals are most likely to affect student outcomes via their policies. Figlio and Sass (2010) show that when a new principal enters a school, that individual is most likely to change policies on teacher incentives, curriculum, and those policies that boost performance of low-achieving students. They further show that the most effective principals focus on policies that boost performance of low-achieving students. Finally, Jacob (2010) shows that principals are likely instrumental in the hiring and firing decisions about teachers, which may trickle down to affect student achievement.</p>
        </div>
       </body>
</html>
